{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc07511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Double Masters 2022 - página 1 de 4\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n",
      "Reiniciando o Python\n",
      "\n",
      "    Double Masters 2022 - página 2 de 4\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n",
      "Reiniciando o Python\n",
      "\n",
      "    Double Masters 2022 - página 3 de 4\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "pppppppppppppppppppp0101010101201101210120101101201012011101101010101110101101101011110121012011010121111010101110101210110111111110120121010101201101012010101201\n",
      "Reiniciando o Python\n",
      "\n",
      "    Double Masters 2022 - página 4 de 4\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "101111110101230110101110101201010101101012101110123010101\n",
      "Reiniciando o Python\n",
      "\n",
      "Reiniciando o Python\n",
      "\n",
      "    Dragon's Maze - página 1 de 2\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "111111111111111111111111111p11111p111111p111p1p11p11111111111111111111111111111111111111111111111111\n",
      "Reiniciando o Python\n",
      "\n",
      "    Dragon's Maze - página 2 de 2\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "p11111111111p1111111111111111p1111111111111p1111111pp11111111111ppp1111\n",
      "Reiniciando o Python\n",
      "\n",
      "Reiniciando o Python\n",
      "\n",
      "    Dragons of Tarkir - página 1 de 3\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111101211111111111\n",
      "Reiniciando o Python\n",
      "\n",
      "    Dragons of Tarkir - página 2 de 3\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "1111111111111111012111111111111111111111101211111111111111111101211111111111111111111111111111111111111111\n",
      "Reiniciando o Python\n",
      "\n",
      "    Dragons of Tarkir - página 3 de 3\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "11111111111111111111111111111012111111111111111111111111\n",
      "Reiniciando o Python\n",
      "\n",
      "Reiniciando o Python\n",
      "\n",
      "    Duel Decks Anthology, Divine vs. Demonic - página 1 de 1\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "11111111111111111111111111111111111111012311111111111110123111\n",
      "Reiniciando o Python\n",
      "\n",
      "Reiniciando o Python\n",
      "\n",
      "    Duel Decks Anthology, Elves vs. Goblins - página 1 de 1\n",
      "123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\n",
      "1111111111101231111111111111111111012311111111"
     ]
    }
   ],
   "source": [
    "#### obter_dados_cards\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import urllib3\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "import gc\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning) #### Desabilitar avisos de segurança do requests\n",
    "\n",
    "\n",
    "#### ___________________________________________________________________________________________________\n",
    "\n",
    "def obter_dados_cards(setUrl, Variation, setName):\n",
    "  #### Criar pasta de imagens, se não existir\n",
    "  image_folder = \"images\"\n",
    "  session2 = None  # Inicializa a variável\n",
    "  session3 = None  # Inicializa a variável\n",
    "\n",
    "  Card = \"\"\n",
    "  Flavor = \"\"\n",
    "  Rarity = \"\"\n",
    "  Artist = \"\"\n",
    "  table_div = None\n",
    "  table_div_cast = None\n",
    "  #### URL do card\n",
    "  url = f\"{setUrl}\"\n",
    "  data = [\"\"] * 16  #### Inicializa a lista com 8 elementos vazios\n",
    "\n",
    "  #### Fazer requisição HTTP\n",
    "  headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "  session2 = requests.Session()\n",
    "  session3 = None\n",
    "  response = session2.get(url, headers=headers, verify=False)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    #### Encontrar variações do card\n",
    "    card_variations_div = soup.find(\"div\", class_=\"variations\")\n",
    "\n",
    "    if card_variations_div:\n",
    "      #### Encontrar todas as variações  \n",
    "      variations = card_variations_div.find_all(\"a\")            \n",
    "      qtdVar = len(variations)\n",
    "      if qtdVar > 1:\n",
    "        variation = variations[Variation - 1]                \n",
    "        variation_url = variation[\"href\"]\n",
    "        variation_url = variation_url.replace(\"/Pages\", \"https://gatherer.wizards.com/Pages\")\n",
    "        #### URL do card \n",
    "        url = variation_url\n",
    "\n",
    "        #### Fazer requisição HTTP\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        session3 = requests.Session()\n",
    "        response = session3.get(url, headers=headers, verify=False)\n",
    "    session2.close()\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    #### Para pegar o id da Carta\n",
    "    match = re.search(r\"multiverseid=(\\d+)\", url)\n",
    "    numero = match.group(1)\n",
    "\n",
    "    # if numero == 497667 or numero == \"497667\":\n",
    "    #   print()\n",
    "    #   breakpoint()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    #### Se não tem variações\n",
    "    #### Encontrar a div que contém a imagem\n",
    "    #### Sem CastOff\n",
    "    card_image_div = soup.find(\"div\", class_=\"cardImage\")\n",
    "    card_image_div_castOff = soup.find(\"table\", class_=\"cardDetails cardComponent\")\n",
    "\n",
    "    if card_image_div:\n",
    "      img_tag = card_image_div.find(\"img\")\n",
    "    elif card_image_div_castOff:\n",
    "      img_tag = card_image_div_castOff.find(\"img\")\n",
    "\n",
    "\n",
    "    if img_tag:\n",
    "      img_url = img_tag[\"src\"]\n",
    "      img_url = img_url.replace(\"../../\", \"https://gatherer.wizards.com/\") \n",
    "      img_alt = img_tag[\"alt\"]\n",
    "      img_name = img_alt + \" - \" + setName + \" - \" + numero + \".jpg\"\n",
    "      img_name = img_name.replace(\"_\", \" \")\n",
    "      img_name = img_name.replace(\"//\",\"&\")\n",
    "      img_name = img_name.replace(\":\",\" \")\n",
    "      img_name = img_name.replace(\"  \",\" \")\n",
    "      \n",
    "      setNameFolder = setName\n",
    "      setNameFolder = setNameFolder.replace(\"_\", \" \")\n",
    "      setNameFolder = setNameFolder.replace(\"//\",\"&\")\n",
    "      setNameFolder = setNameFolder.replace(\":\",\" \")\n",
    "      setNameFolder = setNameFolder.replace(\"  \",\" \")\n",
    "\n",
    "      image_folder = os.path.join(image_folder, setNameFolder)      \n",
    "      os.makedirs(image_folder, exist_ok=True)\n",
    "      img_path = os.path.join(image_folder, img_name)\n",
    "\n",
    "      #### Baixar e salvar a imagem\n",
    "      img_response = requests.get(img_url, headers=headers, verify=False, stream=True)\n",
    "      if img_response.status_code == 200:\n",
    "        with open(img_path, \"wb\") as img_file:\n",
    "          for chunk in img_response.iter_content(chunk_size=8192):  # Baixa e escreve em pedaços de 8KB\n",
    "            img_file.write(chunk)\n",
    "      else:\n",
    "        print(\"Erro ao baixar a imagem.\")\n",
    "    \n",
    "    #### Sem CastOff\n",
    "    table_div = soup.find(\"div\", class_=\"smallGreyMono\", style=\"margin-top: 5px;\")\n",
    "    if table_div:\n",
    "      rows = table_div.find_all(\"div\", class_=\"label\")\n",
    "      values = table_div.find_all(\"div\", class_=\"value\")\n",
    "      \n",
    "      for label, value in zip(rows, values):\n",
    "        key = label.text.strip()\n",
    "        val = value.text.strip()\n",
    "        if key == \"Card Text:\": Card = val\n",
    "        if key == \"Flavor Text:\": Flavor = val\n",
    "        if key == \"Rarity:\": Rarity = val\n",
    "        if key == \"Artist:\": Artist = val\n",
    "        if key == \"Card Number:\": CardNumber = val\n",
    "        if key == \"Expansion:\": Expansion = val\n",
    "      \n",
    "      if Card != \"\": data[0] = Card\n",
    "      if Flavor != \"\": data[1] = Flavor\n",
    "      if Rarity != \"\": data[2] = Rarity\n",
    "      if Artist != \"\": data[3] = Artist\n",
    "      if url != \"\": data[4] = url\n",
    "      if img_path != \"\": data[5] = img_path\n",
    "      if img_url != \"\": data[6] = img_url\n",
    "      if img_name != \"\": data[7] = img_name\n",
    "      if numero != \"\": data[8] = numero\n",
    "      if CardNumber != \"\": data[14] = CardNumber\n",
    "      if Expansion != \"\": data[15] = Expansion\n",
    "\n",
    "    table_div_cast = soup.find_all(\"div\", class_=\"smallGreyMono\", style=None)\n",
    "    counterA = 0\n",
    "    for table_div in table_div_cast:\n",
    "      # table_div = table_div_cast[0]\n",
    "      if table_div and counterA == 0:\n",
    "        rows = table_div.find_all(\"div\", class_=\"label\")\n",
    "        values = table_div.find_all(\"div\", class_=\"value\")\n",
    "        \n",
    "        for label, value in zip(rows, values):\n",
    "          key = label.text.strip()\n",
    "          val = value.text.strip()\n",
    "          if key == \"Card Text:\": Card = val\n",
    "          if key == \"Flavor Text:\": Flavor = val\n",
    "          if key == \"Rarity:\": Rarity = val\n",
    "          if key == \"Artist:\": Artist = val\n",
    "          if key == \"Card Number:\": CardNumber = val\n",
    "          if key == \"Expansion:\": Expansion = val\n",
    "        \n",
    "        if Card != \"\": data[0] = Card\n",
    "        if Flavor != \"\": data[1] = Flavor\n",
    "        if Rarity != \"\": data[2] = Rarity\n",
    "        if Artist != \"\": data[3] = Artist\n",
    "        if url != \"\": data[4] = url\n",
    "        if img_path != \"\": data[5] = img_path\n",
    "        if img_url != \"\": data[6] = img_url\n",
    "        if img_name != \"\": data[7] = img_name\n",
    "        if numero != \"\": data[8] = numero\n",
    "        if CardNumber != \"\": data[14] = CardNumber\n",
    "        if Expansion != \"\": data[15] = Expansion\n",
    "        \n",
    "      if table_div and counterA == 1:\n",
    "        rows = table_div.find_all(\"div\", class_=\"label\")\n",
    "        values = table_div.find_all(\"div\", class_=\"value\")\n",
    "        \n",
    "        CostA = \"0\"\n",
    "        ManaA = \"0\"\n",
    "        TypeA = \"\" \n",
    "        CardA = \"\"\n",
    "        NameA = \"\"  \n",
    "        for label, value in zip(rows, values):\n",
    "          key = label.text.strip()\n",
    "          val = value.text.strip()\n",
    "          if key == \"Card Name:\": NameA = val\n",
    "          if key == \"Mana Cost:\":            \n",
    "            cost_imgsA = value.find_all(\"img\")\n",
    "            CostA = \", \".join(img[\"alt\"] for img in cost_imgsA)\n",
    "          if key == \"Mana Value:\": ManaA = val\n",
    "          if key == \"Types:\": TypeA = val\n",
    "          if key == \"Card Text:\": CardA = val\n",
    "        \n",
    "        if NameA != \"\": data[9] = NameA\n",
    "        if CostA == None: data[10] = CostA  \n",
    "        if CostA != \"\": data[10] = CostA\n",
    "        if ManaA != \"\": data[11] = ManaA\n",
    "        if TypeA != \"\": data[12] = TypeA\n",
    "        if CardA != \"\": data[13] = CardA\n",
    "\n",
    "      counterA += 1\n",
    "\n",
    "\n",
    "  else:\n",
    "    print(\"Erro ao acessar a página.\")\n",
    "\n",
    "  if session2 == None:\n",
    "    session3.close()\n",
    "  else:\n",
    "    session2.close()\n",
    "  return data \n",
    "\n",
    "\n",
    "####___________________________________________________________________________________________\n",
    "\n",
    "\n",
    "#### salvar em Excel\n",
    "\n",
    "def salvar_em_excel(lista_cards):\n",
    "  df_temp = pd.DataFrame(lista_cards, columns=columns)\n",
    "\n",
    "  #### Se o arquivo já existe, carregar; senão, criar um novo\n",
    "  if os.path.exists(excel_file):\n",
    "    wb = load_workbook(excel_file)\n",
    "    ws = wb.active\n",
    "  else:\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.append(columns)  #### Adicionar cabeçalho\n",
    "\n",
    "  #### Adicionar novas linhas ao Excel e imagens\n",
    "  for index, row in df_temp.iterrows():\n",
    "    ws.append(row.tolist())  #### Adiciona os dados\n",
    "\n",
    "  #### Salvar o arquivo Excel atualizado\n",
    "  wb.save(excel_file) \n",
    "\n",
    "\n",
    "#### ___________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "#### obter_lista_cards\n",
    "\n",
    "#### Nome do arquivo Excel\n",
    "excel_file = \"cards_data.xlsx\"\n",
    "\n",
    "#### Colunas do DataFrame\n",
    "columns = [\"Nome\", \"Cost\", \"Total Cost\", \"Type\", \"P\", \"T\", \"Edition\", \"Variações\", #### parte que vem do site compacto\n",
    "           \"Card Text\", \"Flavor Text\", \"Rarity\", \"Artist\", \"Link\", \"Image Path\", \"Image URL\", \"Image Name\", \"id\", #### parte que vem da pagina da carta\n",
    "           \"Nome_A\", \"Cost_A\", \"Total Cost_A\", \"Type_A\", \"Card Text_A\", \"Card Number\", \"Expansion\"] #### parte que vem das cartas com 2 funções\n",
    "\n",
    "#### Carregar IDs existentes, se o arquivo já existir\n",
    "existing_ids = {}\n",
    "if os.path.exists(excel_file):\n",
    "  df_existing = pd.read_excel(excel_file, usecols=[\"id\"])\n",
    "  existing_ids = df_existing[\"id\"].fillna(0).astype(int).tolist()  #### Converter para lista de inteiros\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Arquivo contendo a lista original de sets\n",
    "sets_file = \"sets.txt\"\n",
    "\n",
    "# Ler lista original e os já processados\n",
    "with open(sets_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    sets_list = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Arquivo para armazenar os sets já processados\n",
    "processed_file = \"processed_sets.txt\"\n",
    "\n",
    "### Se houver sets restantes, processar o primeiro e salvar no arquivo  \n",
    "while True:\n",
    "  if os.path.exists(processed_file):\n",
    "      with open(processed_file, \"r\", encoding=\"utf-8\") as f:\n",
    "          processed_list = {line.strip() for line in f.readlines()}\n",
    "  else:\n",
    "      processed_list = set()\n",
    "\n",
    "  # Filtrar sets que ainda não foram processados\n",
    "  remaining_sets = [set_name for set_name in sets_list if set_name not in processed_list]\n",
    "    \n",
    "  if not remaining_sets:  # Se a lista estiver vazia, encerramos o loop\n",
    "      break\n",
    "  \n",
    "  setName = remaining_sets[0]  # Pega o primeiro da lista\n",
    "\n",
    "  #### Carrega a página com a lista de cards\n",
    "  page = 0\n",
    "  formatted_setName = setName.replace(\" \", \"+\")  #### Substituir espaços por '+'\n",
    "  url = f\"https://gatherer.wizards.com/Pages/Search/Default.aspx?sort=name+&page={page}&output=compact&set=[%22{formatted_setName}%22]\"\n",
    "\n",
    "  #### Fazer requisição para a página\n",
    "  session0 = requests.Session()\n",
    "  response = session0.get(url, verify=False)\n",
    "\n",
    "  #### Se a resposta não for válida, interrompe o loop\n",
    "  if response.status_code == 200:  \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    #### Encontrar a div com a classe \"pagincontrols\"\n",
    "    pagin_controls = soup.find(\"div\", class_=\"pagingcontrols\")\n",
    "    if pagin_controls:\n",
    "      links = pagin_controls.find_all(\"a\")\n",
    "      qtdPages = len(links)  #### -1 para não contar o link \"Next\" e começar com 0\n",
    "\n",
    "      if qtdPages <= 1: \n",
    "        qtdPages = 1  \n",
    "      else:\n",
    "        qtdPages = qtdPages - 1\n",
    "    session0.close()\n",
    "\n",
    "  #### Ajuste o número de páginas conforme necessário\n",
    "  for page in range(0, qtdPages):\n",
    "\n",
    "    # Carrega a pagina com links para cada versão do card\n",
    "    url = f\"https://gatherer.wizards.com/Pages/Search/Default.aspx?sort=name+&page={page}&output=compact&set=[%22{formatted_setName}%22]\"\n",
    "\n",
    "    #### Refazer requisição para a página\n",
    "    session1 = requests.Session()\n",
    "    response = session1.get(url, verify=False)\n",
    "\n",
    "    #### Adicionar um pequeno atraso entre as requisições      \n",
    "    time.sleep(2)  \n",
    "\n",
    "    #### Se a resposta não for válida, interrompe o loop\n",
    "    if response.status_code == 200:  \n",
    "      soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "      contador = 0\n",
    "\n",
    "      print(f\"\\n    {setName} - página {page + 1} de {qtdPages}\")\n",
    "      print(\"123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.1234567890123456789.123456789.123456789.123456789.123456789.\")\n",
    "\n",
    "      #### para cada linha da pagina principal\n",
    "      for row in soup.find_all(\"tr\"):\n",
    "        #### Cria uma lista de 1 linha com as informações do card\n",
    "        card= []\n",
    "\n",
    "        #### executar apenas os 5 primeiros cards para testes, desabilitar para fazer o real\n",
    "        contador += 1 \n",
    "        # if contador >= 5: continue  #### executa apenas os 5 primeiros cards\n",
    "\n",
    "        #### vê o conteudo de cada celula\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) >= 6:  #### Garantindo que há ao menos 6 colunas\n",
    "          #### Extrair os dados de texto de cada coluna\n",
    "\n",
    "          name = cols[0].text.strip()\n",
    "          if name == \"Name\" or name == None: continue  #### Ignorar a linha de cabeçalho\n",
    "\n",
    "          # print(f\"    {setName} - página {page} - linha {contador} - {name}\")\n",
    "\n",
    "          #### Para a coluna Link, buscar o atributo href da tag <a> dentro da coluna 0\n",
    "          link_tag = cols[0].find(\"a\")\n",
    "          link = link_tag[\"href\"] if link_tag else \"\"\n",
    "          link = link.replace(\"../\", \"https://gatherer.wizards.com/Pages/\")\n",
    "\n",
    "          # Para pegar o id da Carta\n",
    "          match = re.search(r\"multiverseid=(\\d+)\", link)\n",
    "          numero = match.group(1)\n",
    "\n",
    "          # Verifica se o ID já existe no Excel\n",
    "          #if numero in existing_ids.values():\n",
    "          if int(numero) in existing_ids:\n",
    "            #print(f\"ID {numero} já existe no Excel. Pulando...\")\n",
    "            print(\"p\", end=\"\")\n",
    "            continue\n",
    "\n",
    "          if setName == \"Commander Legends\" and page == 3:\n",
    "            breakpoint()\n",
    "\n",
    "          #### Extrair os dados de texto de cada coluna\n",
    "          type_ = cols[2].text.strip()\n",
    "          P_ = cols[3].text.strip()\n",
    "          T_ = cols[4].text.strip()\n",
    "\n",
    "          #### Para a coluna Cost, buscar todas as tags <img> e extrair o atributo \"alt\"\n",
    "          cost_imgs = cols[1].find_all(\"img\")\n",
    "          cost = \", \".join(img[\"alt\"] for img in cost_imgs)\n",
    "          totalCost = len(cost_imgs)\n",
    "\n",
    "          #### Para a coluna Printings, buscar todas as tags <img> e extrair o atributo \"alt\"\n",
    "          printings_imgs = cols[5].find_all(\"img\")\n",
    "          printings = \", \".join(img[\"alt\"] for img in printings_imgs)\n",
    "          qtdImages = len(printings_imgs)\n",
    "\n",
    "          #### Abre a pagina do Card para pegar a imagem e informações complementares\n",
    "          if qtdImages > 1:\n",
    "            for i in range(0, qtdImages ):\n",
    "              print(i, end=\"\")\n",
    "              card= []\n",
    "              dataRetorno = obter_dados_cards(link, i, setName)\n",
    "              Card = dataRetorno[0]\n",
    "              Flavor = dataRetorno[1]\n",
    "              Rarity = dataRetorno[2]\n",
    "              Artist = dataRetorno[3]\n",
    "              pagina = dataRetorno[4]\n",
    "              img_path = dataRetorno[5]\n",
    "              img_url = dataRetorno[6]\n",
    "              img_name = dataRetorno[7]\n",
    "              numero = dataRetorno[8]\n",
    "              nome_A = dataRetorno[9]\n",
    "              cost_A = dataRetorno[10]\n",
    "              totalCost_A = dataRetorno[11]\n",
    "              type_A = dataRetorno[12]\n",
    "              Card_Text_A = dataRetorno[13]\n",
    "              Card_Number = dataRetorno[14]\n",
    "              Expansion = dataRetorno[15]\n",
    "              # adicionar o id à lista de ids existentes\n",
    "              try:\n",
    "                existing_ids.append(int(numero))\n",
    "              except:\n",
    "                print(f\"Erro ao converter o ID {numero} para inteiro.\")\n",
    "                print(f\"{setName} - {pagina} - {name} - {numero} - \\n{link}  \\n{nome_A} - {Card_Text_A}\")\n",
    "                continue\n",
    "\n",
    "              #### Adicionar o card à lista\n",
    "              card.append([name, cost, totalCost, type_, P_, T_, printings, i+1, \n",
    "                          Card, Flavor, Rarity, Artist, pagina, img_path, img_url, img_name, int(numero), \n",
    "                          nome_A, cost_A, totalCost_A, type_A, Card_Text_A, Card_Number, Expansion])\n",
    "              salvar_em_excel(card)  #### Salvar os dados do card no Excel\n",
    "\n",
    "          else:\n",
    "            print(\"1\", end=\"\")\n",
    "            dataRetorno = obter_dados_cards(link, 1, setName)\n",
    "            Card = dataRetorno[0]\n",
    "            Flavor = dataRetorno[1]\n",
    "            Rarity = dataRetorno[2]\n",
    "            Artist = dataRetorno[3]\n",
    "            pagina = dataRetorno[4]\n",
    "            img_path = dataRetorno[5]\n",
    "            img_url = dataRetorno[6]\n",
    "            img_name = dataRetorno[7]\n",
    "            numero = dataRetorno[8]\n",
    "            nome_A = dataRetorno[9]\n",
    "            cost_A = dataRetorno[10]\n",
    "            totalCost_A = dataRetorno[11]\n",
    "            type_A = dataRetorno[12]\n",
    "            Card_Text_A = dataRetorno[13]\n",
    "            Card_Number = dataRetorno[14]\n",
    "            Expansion = dataRetorno[15]\n",
    "            # adicionar o id à lista de ids existentes\n",
    "            try:\n",
    "              existing_ids.append(int(numero))\n",
    "            except:\n",
    "              print(f\"Erro ao converter o ID {numero} para inteiro.\")\n",
    "              print(f\"{setName} - {pagina} - {name} - {numero} - \\n{link}  \\n{nome_A} - {Card_Text_A}\")\n",
    "              continue\n",
    "            #### Adicionar o card à lista\n",
    "            card.append([name, cost, totalCost, type_, P_, T_, printings, 1, \n",
    "                        Card, Flavor, Rarity, Artist, pagina, img_path, img_url, img_name, int(numero), \n",
    "                        nome_A, cost_A, totalCost_A, type_A, Card_Text_A, Card_Number, Expansion])\n",
    "            salvar_em_excel(card)  #### Salvar os dados do card no Excel\n",
    "\n",
    "    session1.close()  #### Fechar a sessão do requests\n",
    "    gc.collect()\n",
    "\n",
    "    # Reiniciar Python após processar um set\n",
    "    print(\"\\nReiniciando o Python\")\n",
    "    quit()\n",
    "    os.system(\"MTG.ipynb\")\n",
    "  # fim do for page in range(0, qtdPages):\n",
    "\n",
    "  # Registrar o set como processado\n",
    "  with open(processed_file, \"a\", encoding=\"utf-8\") as f:\n",
    "      f.write(setName + \"\\n\")\n",
    "\n",
    "  #### Reiniciar Python após processar um set\n",
    "  print(\"\\nReiniciando o Python\")\n",
    "  quit()\n",
    "  os.system(\"MTG.ipynb\")\n",
    "\n",
    "\n",
    "  remaining_sets = [set_name for set_name in sets_list if set_name not in processed_list]\n",
    "\n",
    "\n",
    "print(\"Todos os sets foram processados!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
